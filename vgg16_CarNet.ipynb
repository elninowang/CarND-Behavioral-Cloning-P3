{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, merge, Input, BatchNormalization\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.data_utils import get_file\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.186262807718055 -0.004452897419339064 1.0 -1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>center</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>dir</th>\n",
       "      <th>acc</th>\n",
       "      <th>nacc</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>center_2017_01_05_10_33_07_558.jpg</td>\n",
       "      <td>left_2017_01_05_10_33_07_558.jpg</td>\n",
       "      <td>right_2017_01_05_10_33_07_558.jpg</td>\n",
       "      <td>-46.68390</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.14583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>center_2017_01_05_10_33_07_666.jpg</td>\n",
       "      <td>left_2017_01_05_10_33_07_666.jpg</td>\n",
       "      <td>right_2017_01_05_10_33_07_666.jpg</td>\n",
       "      <td>-82.77869</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.10305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>center_2017_01_05_10_33_07_769.jpg</td>\n",
       "      <td>left_2017_01_05_10_33_07_769.jpg</td>\n",
       "      <td>right_2017_01_05_10_33_07_769.jpg</td>\n",
       "      <td>-51.98100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.18893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>center_2017_01_05_10_33_07_871.jpg</td>\n",
       "      <td>left_2017_01_05_10_33_07_871.jpg</td>\n",
       "      <td>right_2017_01_05_10_33_07_871.jpg</td>\n",
       "      <td>-21.23459</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.19710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>center_2017_01_05_10_33_07_987.jpg</td>\n",
       "      <td>left_2017_01_05_10_33_07_987.jpg</td>\n",
       "      <td>right_2017_01_05_10_33_07_987.jpg</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.18751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               center                              left  \\\n",
       "0  center_2017_01_05_10_33_07_558.jpg  left_2017_01_05_10_33_07_558.jpg   \n",
       "1  center_2017_01_05_10_33_07_666.jpg  left_2017_01_05_10_33_07_666.jpg   \n",
       "2  center_2017_01_05_10_33_07_769.jpg  left_2017_01_05_10_33_07_769.jpg   \n",
       "3  center_2017_01_05_10_33_07_871.jpg  left_2017_01_05_10_33_07_871.jpg   \n",
       "4  center_2017_01_05_10_33_07_987.jpg  left_2017_01_05_10_33_07_987.jpg   \n",
       "\n",
       "                               right       dir  acc  nacc     speed  \n",
       "0  right_2017_01_05_10_33_07_558.jpg -46.68390  1.0   0.0  30.14583  \n",
       "1  right_2017_01_05_10_33_07_666.jpg -82.77869  1.0   0.0  30.10305  \n",
       "2  right_2017_01_05_10_33_07_769.jpg -51.98100  1.0   0.0  30.18893  \n",
       "3  right_2017_01_05_10_33_07_871.jpg -21.23459  1.0   0.0  30.19710  \n",
       "4  right_2017_01_05_10_33_07_987.jpg   0.00000  1.0   0.0  30.18751  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/ext/Data/ypw/driving_log.csv', skipinitialspace=True)\n",
    "df.columns = ['center', 'left', 'right', 'dir', 'acc', 'nacc', 'speed']\n",
    "df = df.drop((df[df['acc'] != 1]).index)\n",
    "df = df.drop((df[df['speed'] < 30.1]).index)\n",
    "print(df['speed'].mean(), df['dir'].mean(), df['dir'].max(), df['dir'].min())\n",
    "df = df.reset_index(drop=True)\n",
    "df['dir'] = df['dir'] * 100\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>center_2017_01_05_10_33_07_558.jpg</td>\n",
       "      <td>-46.68390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>center_2017_01_05_10_33_07_666.jpg</td>\n",
       "      <td>-82.77869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>center_2017_01_05_10_33_07_769.jpg</td>\n",
       "      <td>-51.98100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>center_2017_01_05_10_33_07_871.jpg</td>\n",
       "      <td>-21.23459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>center_2017_01_05_10_33_07_987.jpg</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             filename       dir\n",
       "0  center_2017_01_05_10_33_07_558.jpg -46.68390\n",
       "1  center_2017_01_05_10_33_07_666.jpg -82.77869\n",
       "2  center_2017_01_05_10_33_07_769.jpg -51.98100\n",
       "3  center_2017_01_05_10_33_07_871.jpg -21.23459\n",
       "4  center_2017_01_05_10_33_07_987.jpg   0.00000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['left', 'right', 'acc', 'nacc', 'speed'], axis=1)\n",
    "df.columns = ['filename', 'dir']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class Smooth:\n",
    "    def __init__(self, windowsize=50):\n",
    "        self.window_size = windowsize\n",
    "        self.data = np.zeros(self.window_size, dtype=np.float32)\n",
    "        self.index = 0\n",
    "    \n",
    "    def __iadd__(self, x):\n",
    "        self.data[self.index % self.window_size] = x\n",
    "        self.index += 1\n",
    "        return self\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.data[:self.index].mean())\n",
    "    \n",
    "    def __float__(self):\n",
    "        return float(self.data[:self.index].mean())\n",
    "\n",
    "class BatchGenerator:\n",
    "    def __init__(self, df, batch, image_shape):\n",
    "        self.df = df\n",
    "        self.batch = batch\n",
    "        self.image_shape = image_shape\n",
    "        self.num = len(self.df.index)\n",
    "    \n",
    "    def next(self):\n",
    "        X = np.ndarray((self.batch, self.image_shape[1], self.image_shape[0], 3), dtype=np.float32)\n",
    "        y = np.ndarray((self.batch, 1), dtype=np.float32)\n",
    "        image_shape = self.image_shape\n",
    "        \n",
    "        for i, index in enumerate(random.sample(self.df.index.tolist(), self.batch)):\n",
    "            img = cv2.imread(\"/ext/Data/ypw/IMG/\" + self.df.loc[index]['filename'])\n",
    "            img = cv2.resize(img, image_shape)\n",
    "            X[i] = img\n",
    "            y[i] = self.df.loc[index]['dir']\n",
    "\n",
    "        return X, y\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21417 1128\n"
     ]
    }
   ],
   "source": [
    "batch = 64\n",
    "image_shape = (128, 128)\n",
    "\n",
    "df_train, df_val = train_test_split(df, test_size=0.05, random_state=42)\n",
    "train = BatchGenerator(df_train, batch, image_shape)\n",
    "val = BatchGenerator(df_val, batch, image_shape)\n",
    "\n",
    "print(train.num, val.num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "img_input = Input(shape=(image_shape[1], image_shape[0], 3))\n",
    "base_model = VGG16(weights='imagenet', input_tensor=img_input, include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jidou/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:8: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "x = base_model.output\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "x = Dense(1)(x)\n",
    "\n",
    "model = Model(input=base_model.input, output=x)\n",
    "\n",
    "model.compile(loss='mse', optimizer='adadelta', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              16779264  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 35,692,353\n",
      "Trainable params: 35,692,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x7f356009a7c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(range(len(model.layers)), model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.025709219858156027 loss=339.80700250720304\n"
     ]
    }
   ],
   "source": [
    "val_num = len(df_val.index)\n",
    "X_valid = np.ndarray((val_num, image_shape[1], image_shape[0], 3), dtype=np.float32)\n",
    "y_valid = np.ndarray((val_num, 1), dtype=np.float32)\n",
    "for i, index in enumerate(df_val.index):\n",
    "    img = cv2.imread(\"/ext/Data/ypw/IMG/\" + df_val.loc[index]['filename'])\n",
    "    img = cv2.resize(img, image_shape)\n",
    "    X_valid[i] = img\n",
    "    y_valid[i] = df_val.loc[index]['dir']\n",
    "\n",
    "def validation():\n",
    "    loss, acc = model.evaluate(X_valid, y_valid, verbose=0)\n",
    "    return acc, loss\n",
    "\n",
    "acc,loss = validation()\n",
    "print(\"acc={} loss={}\".format(acc,loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def train_one_batch(generator):\n",
    "    acc = Smooth()\n",
    "    loss = Smooth()\n",
    "    batch_num = generator.num//batch\n",
    "    pbar = tqdm(range(batch_num))\n",
    "    for i in pbar:\n",
    "        X,y = generator.next()\n",
    "        _loss, _acc = model.train_on_batch(X, y)\n",
    "        acc += _acc\n",
    "        loss += _loss\n",
    "        \n",
    "        if i != batch_num-1:\n",
    "            pbar.set_description(\"train loss: %.4f\" % loss)\n",
    "        else:\n",
    "            pbar.set_description(\"train loss: %.4f\\t valid loss: %.4f\\t\" % (loss, validation()[1]))\n",
    "\n",
    "def transfer_learning(top_num=-4, epoch=10, optimizer='adadelta'):\n",
    "    for layer in model.layers[:top_num]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    for layer in model.layers[top_num:]:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        train_one_batch(train)\n",
    "        \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 155.9977\t valid loss: 183.4593\t: 100%|██████████| 334/334 [00:49<00:00,  1.68it/s]\n",
      "train loss: 142.4862\t valid loss: 172.8355\t: 100%|██████████| 334/334 [00:49<00:00,  1.77it/s]\n",
      "train loss: 133.2051\t valid loss: 166.9191\t: 100%|██████████| 334/334 [00:49<00:00,  1.78it/s]\n",
      "train loss: 112.5239\t valid loss: 167.6074\t: 100%|██████████| 334/334 [00:49<00:00,  1.81it/s]\n",
      "train loss: 111.0106\t valid loss: 170.0515\t: 100%|██████████| 334/334 [00:49<00:00,  1.75it/s]\n",
      "train loss: 98.8203\t valid loss: 165.1724\t: 100%|██████████| 334/334 [00:49<00:00,  1.74it/s]\n"
     ]
    }
   ],
   "source": [
    "transfer_learning(18, epoch=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 165.1723\t valid loss: 599.9080\t: 100%|██████████| 334/334 [01:10<00:00,  1.26it/s]\n",
      "train loss: 149.6473\t valid loss: 166.7473\t: 100%|██████████| 334/334 [01:09<00:00,  1.34it/s]\n",
      "train loss: 129.3146\t valid loss: 173.4929\t: 100%|██████████| 334/334 [01:10<00:00,  1.38it/s]\n",
      "train loss: 124.0688\t valid loss: 159.6310\t: 100%|██████████| 334/334 [01:09<00:00,  1.33it/s]\n",
      "train loss: 115.3497\t valid loss: 165.5708\t: 100%|██████████| 334/334 [01:09<00:00,  1.42it/s]\n",
      "train loss: 106.3459\t valid loss: 162.6810\t: 100%|██████████| 334/334 [01:09<00:00,  1.34it/s]\n",
      "train loss: 103.7747\t valid loss: 195.3994\t: 100%|██████████| 334/334 [01:09<00:00,  1.42it/s]\n",
      "train loss: 88.1034\t valid loss: 180.2756\t: 100%|██████████| 334/334 [01:09<00:00,  1.30it/s]\n",
      "train loss: 76.4132\t valid loss: 167.5006\t: 100%|██████████| 334/334 [01:10<00:00,  1.30it/s]\n",
      "train loss: 72.3272\t valid loss: 199.9035\t: 100%|██████████| 334/334 [01:09<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "transfer_learning(14, epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x7f34c7f16048>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val, y_val = val.next()\n",
    "y_pred = model.predict(X_val)\n",
    "delta = y_val - y_pred\n",
    "\n",
    "zip(y_val.tolist(), y_pred.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved\n"
     ]
    }
   ],
   "source": [
    "model.save('vgg16_model.h5', overwrite=True)\n",
    "print(\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json writed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jidou/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:13: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "img_input = Input(shape=(image_shape[1], image_shape[0], 3))\n",
    "base_model = VGG16(weights='imagenet', input_tensor=img_input, include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "x = Dense(1)(x)\n",
    "\n",
    "model = Model(input=base_model.input, output=x)\n",
    "\n",
    "model.compile(loss='mse', optimizer='adadelta', metrics=['accuracy'])\n",
    "\n",
    "with open('vgg16_model.json', 'w') as f:\n",
    "    f.write(model.to_json())\n",
    "    print(\"json writed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
